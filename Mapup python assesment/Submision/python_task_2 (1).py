# -*- coding: utf-8 -*-
"""Python_task_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ovn5QF8gpLow0yB8-3BQLFUhg9kPjUE2
"""

import pandas as pd

# Load datasets
dataset_1 = pd.read_csv('/content/dataset-1.csv')
dataset_2 = pd.read_csv('/content/dataset-2.csv', encoding='latin1')
input_file = '/content/dataset-2.csv'
output_file = '/content/dataset-2_fixed.csv'

# Open the input file, fix encoding issues, and write to a new file
with open(input_file, 'rb') as f:
    content = f.read().decode('latin1', errors='replace')

with open(output_file, 'w', encoding='utf-8') as f:
    f.write(content)

# Now read the fixed CSV file using pandas
dataset_3 = pd.read_csv(output_file)

dataset_1.head()  # Display first few rows of dataset_1
dataset_1.info()  # Get information about dataset_1 columns and data types
print(dataset_1.columns)  # Print all column names in dataset_1
selected_columns = dataset_1[['id_1', 'id_2', 'route', 'moto', 'car', 'rv', 'bus', 'truck']]

def generate_car_matrix(df)->pd.DataFrame:
    """
    Creates a DataFrame  for id combinations.

    Args:
        df (pandas.DataFrame)

    Returns:
        pandas.DataFrame: Matrix generated with 'car' values,
                          where 'id_1' and 'id_2' are used as indices and columns respectively.
    """
    # Write your logic here
    # Load dataset-1.csv into a DataFrame
dataset_1 = pd.read_csv('/content/dataset-1.csv')

def generate_car_matrix(data):
    # Pivot the DataFrame to get 'car' values with 'id_1' as index and 'id_2' as columns
    car_matrix = data.pivot(index='id_1', columns='id_2', values='car')

    # Set diagonal values to 0
    for idx in car_matrix.index:
        car_matrix.at[idx, idx] = 0

    return car_matrix

# Call the function with the dataset and store the result in a variable
result_matrix = generate_car_matrix(dataset_1)

# Display the resulting matrix
print(result_matrix)




def get_type_count(df)->dict:
    """
    Categorizes 'car' values into types and returns a dictionary of counts.

    Args:
        df (pandas.DataFrame)

    Returns:
        dict: A dictionary with car types as keys and their counts as values.
    """
    # Write your logic here
import pandas as pd

def get_type_count(df):
    # Add a new categorical column 'car_type' based on conditions
    df['car_type'] = pd.cut(df['car'], bins=[float('-inf'), 15, 25, float('inf')],
                            labels=['low', 'medium', 'high'], right=False)

    # Calculate counts for each 'car_type' category
    type_counts = df['car_type'].value_counts().sort_index()

    # Convert counts to a dictionary and return, sorted alphabetically
    result_dict = type_counts.to_dict()
    return result_dict

# Load dataset-1.csv into a DataFrame
dataset_1 = pd.read_csv('/content/dataset-1.csv')
import matplotlib.pyplot as plt

# Assuming type_count_result contains the dictionary of car type counts
labels, counts = zip(*type_count_result.items())

plt.bar(labels, counts)
plt.xlabel('Car Types')
plt.ylabel('Count')
plt.title('Distribution of Car Types')
plt.show()

# Call the function with the dataset and store the result in a variable
type_count_result = get_type_count(dataset_1)

# Display the resulting dictionary
print(type_count_result)



def get_bus_indexes(df)->list:
    """
    Returns the indexes where the 'bus' values are greater than twice the mean.

    Args:
        df (pandas.DataFrame)

    Returns:
        list: List of indexes where 'bus' values exceed twice the mean.
    """
    # Write your logic here

def get_bus_indexes(df):
    # Calculate the mean value of the 'bus' column
    bus_mean = df['bus'].mean()

    # Find indices where 'bus' values exceed twice the mean
    bus_indices = df[df['bus'] > 2 * bus_mean].index.tolist()

    # Sort the indices in ascending order
    bus_indices.sort()

    return bus_indices

# Load dataset-1.csv into a DataFrame
dataset_1 = pd.read_csv('/content/dataset-1.csv')

# Call the function with the dataset and store the result in a variable
bus_indexes = get_bus_indexes(dataset_1)

# Display the resulting list of indices
print(bus_indexes)
# Assuming bus_indexes contains the list of indices
filtered_data = dataset_1.loc[bus_indexes]

# Calculate the mean of a different column 'some_column' for rows at the obtained indices
mean_some_column = dataset_1.loc[bus_indexes, 'bus'].mean()

# Display the calculated mean
print("Mean of 'some_column' for selected rows:", mean_some_column)

# Display the filtered data
print(filtered_data)


def filter_routes(df)->list:
    """
    Filters and returns routes with average 'truck' values greater than 7.

    Args:
        df (pandas.DataFrame)

    Returns:
        list: List of route names with average 'truck' values greater than 7.
    """
    # Write your logic here
    import pandas as pd

def filter_routes(df):
    # Calculate the average 'truck' values for each route
    avg_truck_values = df.groupby('route')['truck'].mean()

    # Filter routes where average 'truck' values are greater than 7
    filtered_routes = avg_truck_values[avg_truck_values > 7].index.tolist()

    # Sort the list of routes in ascending order
    filtered_routes.sort()

    return filtered_routes

# Load dataset-1.csv into a DataFrame
dataset_1 = pd.read_csv('/content/dataset-1.csv')

# Call the function with the dataset and store the result in a variable
filtered_routes_list = filter_routes(dataset_1)

# Display the resulting list of routes
print(filtered_routes_list)

import matplotlib.pyplot as plt

# Assuming filtered_routes_list contains the list of routes
plt.bar(range(len(filtered_routes_list)), filtered_routes_list)
plt.xlabel('Routes')
plt.ylabel('Average Truck Values')
plt.title('Routes with Average Truck Values > 7')
plt.show()
# Assuming filtered_routes_list contains the list of routes
filtered_data = dataset_1[dataset_1['route'].isin(filtered_routes_list)]

# Display the filtered data
print(filtered_data)


def multiply_matrix(matrix)->pd.DataFrame:
    """
    Multiplies matrix values with custom conditions.

    Args:
        matrix (pandas.DataFrame)

    Returns:
        pandas.DataFrame: Modified matrix with values multiplied based on custom conditions.
    """
    # Write your logic here
import pandas as pd

def multiply_matrix(matrix):
    # Make a copy of the input DataFrame to avoid modifying the original
    modified_matrix = matrix.copy()

    # Iterate through the DataFrame values and apply multiplication rules
    for idx in modified_matrix.index:
        for col in modified_matrix.columns:
            value = modified_matrix.at[idx, col]
            if value > 20:
                modified_matrix.at[idx, col] = round(value * 0.75, 1)
            else:
                modified_matrix.at[idx, col] = round(value * 1.25, 1)

    return modified_matrix

# Assuming 'car_matrix' is the DataFrame obtained from Question 1
# Call the function with the DataFrame and store the modified DataFrame
modified_car_matrix = multiply_matrix(result_matrix)

# Display the modified DataFrame
print(result_matrix)

print(modified_car_matrix.head())
# Perform statistical analysis on modified values
mean_values = modified_car_matrix.mean()
print("Mean values of modified matrix:\n", mean_values)

# Save modified DataFrame to a new file
modified_car_matrix.to_csv('modified_car_matrix.csv', index=False)  # Save to a CSV file


def time_check(df)->pd.Series:
    """
    Use shared dataset-2 to verify the completeness of the data by checking whether the timestamps for each unique (`id`, `id_2`) pair cover a full 24-hour and 7 days period

    Args:
        df (pandas.DataFrame)

    Returns:
        pd.Series: return a boolean series
    """
    # Write your logic here
df = pd.DataFrame(data)
print(df)
import pandas as pd

def verify_time_completeness_for_row(row):
    # Create a DataFrame with the specific row
    df = pd.DataFrame([row], columns=[
        'id_1', 'name', 'id_2', 'startDay', 'startTime', 'endDay', 'endTime',
        'able2Hov2', 'able2Hov3', 'able3Hov2', 'able3Hov3', 'able5Hov2', 'able5Hov3', 'able4Hov2', 'able4Hov3'
    ])

    # Convert time columns to datetime objects
    df['startTime'] = pd.to_datetime(df['startTime'])
    df['endTime'] = pd.to_datetime(df['endTime'])

    # Convert startDay and endDay to the corresponding days of the week
    days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    start_day_index = days_of_week.index(df['startDay'].values[0])
    end_day_index = days_of_week.index(df['endDay'].values[0])

    # Calculate the number of days between the start and end days
    days_difference = end_day_index - start_day_index + 1 if end_day_index >= start_day_index else 7 + end_day_index - start_day_index + 1

    # Calculate the duration between startTime and endTime
    duration = (df['endTime'].values[0] - df['startTime'].values[0])

    # Check if the time period covers a full 24-hour period and spans all 7 days
    return duration >= pd.Timedelta(days=1) and days_difference == 7

# Sample row data
row_data = [1040000, 'Montgomery', -1, 'Monday', '5:00:00', 'Wednesday', '10:00:00', 3, 3, -1, -1, 3, 3, 3, 3]

# Verify time completeness for the specific row
time_completeness_row_check = verify_time_completeness_for_row(row_data)
print("Time Completeness Check for Row:", time_completeness_row_check)

