{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 341 entries, 0 to 340\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   id_1    341 non-null    int64  \n",
      " 1   id_2    341 non-null    int64  \n",
      " 2   route   341 non-null    int64  \n",
      " 3   moto    341 non-null    float64\n",
      " 4   car     341 non-null    float64\n",
      " 5   rv      341 non-null    float64\n",
      " 6   bus     341 non-null    float64\n",
      " 7   truck   341 non-null    float64\n",
      "dtypes: float64(5), int64(3)\n",
      "memory usage: 21.4 KB\n",
      "Index(['id_1', 'id_2', 'route', 'moto', 'car', 'rv', 'bus', 'truck'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Python_task_2.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1Ovn5QF8gpLow0yB8-3BQLFUhg9kPjUE2\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "dataset_1 = pd.read_csv(r\"C:\\Users\\reddy\\Desktop\\dataset-1.csv\")\n",
    "dataset_2 = pd.read_csv(r\"C:\\Users\\reddy\\Desktop\\dataset-2.csv\", encoding='latin1')\n",
    "input_file = r\"C:\\Users\\reddy\\Desktop\\dataset-2.csv\"\n",
    "output_file = r\"C:\\Users\\reddy\\Desktop\\dataset-2_fixed.csv\"\n",
    "\n",
    "# Open the input file, fix encoding issues, and write to a new file\n",
    "with open(input_file, 'rb') as f:\n",
    "    content = f.read().decode('latin1', errors='replace')\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(content)\n",
    "\n",
    "# Now read the fixed CSV file using pandas\n",
    "dataset_3 = pd.read_csv(output_file)\n",
    "\n",
    "dataset_1.head()  # Display first few rows of dataset_1\n",
    "dataset_1.info()  # Get information about dataset_1 columns and data types\n",
    "print(dataset_1.columns)  # Print all column names in dataset_1\n",
    "selected_columns = dataset_1[['id_1', 'id_2', 'route', 'moto', 'car', 'rv', 'bus', 'truck']]\n",
    "\n",
    "def generate_car_matrix(df)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a DataFrame  for id combinations.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame)\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Matrix generated with 'car' values,\n",
    "                          where 'id_1' and 'id_2' are used as indices and columns respectively.\n",
    "    \"\"\"\n",
    "    # Write your logic here\n",
    "    # Load dataset-1.csv into a DataFrame\n",
    "    dataset_1 = pd.read_csv(r\"C:\\Users\\reddy\\Desktop\\dataset-1.csv\")\n",
    "\n",
    "    def generate_car_matrix(data):\n",
    "        # Pivot the DataFrame to get 'car' values with 'id_1' as index and 'id_2' as columns\n",
    "        car_matrix = data.pivot(index='id_1', columns='id_2', values='car')\n",
    "\n",
    "        # Set diagonal values to 0\n",
    "        for idx in car_matrix.index:\n",
    "            car_matrix.at[idx, idx] = 0\n",
    "\n",
    "        return car_matrix\n",
    "\n",
    "    # Call the function with the dataset and store the result in a variable\n",
    "    result_matrix = generate_car_matrix(dataset_1)\n",
    "\n",
    "    # Display the resulting matrix\n",
    "    print(result_matrix)\n",
    "\n",
    "def get_type_count(df)->dict:\n",
    "    \"\"\"\n",
    "    Categorizes 'car' values into types and returns a dictionary of counts.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame)\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with car types as keys and their counts as values.\n",
    "    \"\"\"\n",
    "    # Write your logic here\n",
    "    import pandas as pd\n",
    "\n",
    "    def get_type_count(df):\n",
    "        # Add a new categorical column 'car_type' based on conditions\n",
    "        df['car_type'] = pd.cut(df['car'], bins=[float('-inf'), 15, 25, float('inf')],\n",
    "                                labels=['low', 'medium', 'high'], right=False)\n",
    "\n",
    "        # Calculate counts for each 'car_type' category\n",
    "        type_counts = df['car_type'].value_counts().sort_index()\n",
    "\n",
    "        # Convert counts to a dictionary and return, sorted alphabetically\n",
    "        result_dict = type_counts.to_dict()\n",
    "        return result_dict\n",
    "\n",
    "    # Load dataset-1.csv into a DataFrame\n",
    "    dataset_1 = pd.read_csv(r\"C:\\Users\\reddy\\Desktop\\dataset-1.csv\")\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Assuming type_count_result contains the dictionary of car type counts\n",
    "    labels, counts = zip(*type_count_result.items())\n",
    "\n",
    "    plt.bar(labels, counts)\n",
    "    plt.xlabel('Car Types')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Distribution of Car Types')\n",
    "    plt.show()\n",
    "\n",
    "    # Call the function with the dataset and store the result in a variable\n",
    "    type_count_result = get_type_count(dataset_1)\n",
    "\n",
    "    # Display the resulting dictionary\n",
    "    print(type_count_result)\n",
    "\n",
    "def get_bus_indexes(df)->list:\n",
    "    \"\"\"\n",
    "    Returns the indexes where the 'bus' values are greater than twice the mean.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame)\n",
    "\n",
    "    Returns:\n",
    "        list: List of indexes where 'bus' values exceed twice the mean.\n",
    "    \"\"\"\n",
    "    # Write your logic here\n",
    "\n",
    "    def get_bus_indexes(df):\n",
    "        # Calculate the mean value of the 'bus' column\n",
    "        bus_mean = df['bus'].mean()\n",
    "\n",
    "        # Find indices where 'bus' values exceed twice the mean\n",
    "        bus_indices = df[df['bus'] > 2 * bus_mean].index.tolist()\n",
    "\n",
    "        # Sort the indices in ascending order\n",
    "        bus_indices.sort()\n",
    "\n",
    "        return bus_indices\n",
    "\n",
    "    # Load dataset-1.csv into a DataFrame\n",
    "    dataset_1 = pd.read_csv(r\"C:\\Users\\reddy\\Desktop\\dataset-1.csv\")\n",
    "\n",
    "    # Call the function with the dataset and store the result in a variable\n",
    "    bus_indexes = get_bus_indexes(dataset_1)\n",
    "\n",
    "    # Display the resulting list of indices\n",
    "    print(bus_indexes)\n",
    "\n",
    "    # Assuming bus_indexes contains the list of indices\n",
    "    filtered_data = dataset_1.loc[bus_indexes]\n",
    "\n",
    "    # Calculate the mean of a different column 'some_column' for rows at the obtained indices\n",
    "    mean_some_column = dataset_1.loc[bus_indexes, 'bus'].mean()\n",
    "\n",
    "    # Display the calculated mean\n",
    "    print(\"Mean of 'some_column' for selected rows:\", mean_some_column)\n",
    "\n",
    "    # Display the filtered data\n",
    "    print(filtered_data)\n",
    "\n",
    "def filter_routes(df)->list:\n",
    "    \"\"\"\n",
    "    Filters and returns routes with average 'truck' values greater than 7.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame)\n",
    "\n",
    "    Returns:\n",
    "        list: List of route names with average 'truck' values greater than 7.\n",
    "    \"\"\"\n",
    "    # Write your logic here\n",
    "    import pandas as pd\n",
    "\n",
    "    def filter_routes(df):\n",
    "        # Calculate the average 'truck' values for each route\n",
    "        avg_truck_values = df.groupby('route')['truck'].mean()\n",
    "\n",
    "        # Filter routes where average 'truck' values are greater than 7\n",
    "        filtered_routes = avg_truck_values[avg_truck_values > 7].index.tolist()\n",
    "\n",
    "        # Sort the list of routes in ascending order\n",
    "        filtered_routes.sort()\n",
    "\n",
    "        return filtered_routes\n",
    "\n",
    "    # Load dataset-1.csv into a DataFrame\n",
    "    dataset_1 = pd.read_csv(r\"C:\\Users\\reddy\\Desktop\\dataset-1.csv\")\n",
    "\n",
    "    # Call the function with the dataset and store the result in a variable\n",
    "    filtered_routes_list = filter_routes(dataset_1)\n",
    "\n",
    "    # Display the resulting list of routes\n",
    "    print(filtered_routes_list)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Assuming filtered_routes_list contains the list of routes\n",
    "    plt.bar(range(len(filtered_routes_list)), filtered_routes_list)\n",
    "    plt.xlabel('Routes')\n",
    "    plt.ylabel('Average Truck Values')\n",
    "    plt.title('Routes with Average Truck Values > 7')\n",
    "    plt.show()\n",
    "\n",
    "    # Assuming filtered_routes_list contains the list of routes\n",
    "    filtered_data = dataset_1[dataset_1['route'].isin(filtered_routes_list)]\n",
    "\n",
    "    # Display the filtered data\n",
    "    print(filtered_data)\n",
    "\n",
    "def multiply_matrix(matrix)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Multiplies matrix values with custom conditions.\n",
    "\n",
    "    Args:\n",
    "        matrix (pandas.DataFrame)\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Modified matrix with values multiplied based on custom conditions.\n",
    "    \"\"\"\n",
    "    # Write your logic here\n",
    "    import pandas as pd\n",
    "\n",
    "    def multiply_matrix(matrix):\n",
    "        # Make a copy of the input DataFrame to avoid modifying the original\n",
    "        modified_matrix = matrix.copy()\n",
    "\n",
    "        # Iterate through the DataFrame values and apply multiplication rules\n",
    "        for idx in modified_matrix.index:\n",
    "            for col in modified_matrix.columns:\n",
    "                value = modified_matrix.at[idx, col]\n",
    "                if value > 20:\n",
    "                    modified_matrix.at[idx, col] = round(value * 0.75, 1)\n",
    "                else:\n",
    "                    modified_matrix.at[idx, col] = round(value * 1.25, 1)\n",
    "\n",
    "        return modified_matrix\n",
    "\n",
    "    # Assuming 'car_matrix' is the DataFrame obtained from Question 1\n",
    "    # Call the function with the DataFrame and store the modified DataFrame\n",
    "    modified_car_matrix = multiply_matrix(result_matrix)\n",
    "\n",
    "    # Display the modified DataFrame\n",
    "    print(result_matrix)\n",
    "\n",
    "    print(modified_car_matrix.head())\n",
    "\n",
    "    # Perform statistical analysis on modified values\n",
    "    mean_values = modified_car_matrix.mean()\n",
    "    print(\"Mean values of modified matrix:\\n\", mean_values)\n",
    "\n",
    "    # Save modified DataFrame to a new file\n",
    "    modified_car_matrix.to_csv(r\"C:\\Users\\reddy\\Desktop\\modified_car_matrix.csv\", index=False)  # Save to a CSV file\n",
    "\n",
    "def time_check(df)->pd.Series:\n",
    "    \"\"\"\n",
    "    Use shared dataset-2 to verify the completeness of the data by checking whether the timestamps for each unique (`id`, `id_2`) pair cover a full 24-hour and 7 days period\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame)\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: return a boolean series\n",
    "    \"\"\"\n",
    "    # Write your logic here\n",
    "    df = pd.DataFrame(data)\n",
    "    print(df)\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    def verify_time_completeness_for_row(row):\n",
    "        # Create a DataFrame with the specific row\n",
    "        df = pd.DataFrame([row], columns=[\n",
    "            'id_1', 'name', 'id_2', 'startDay', 'startTime', 'endDay', 'endTime',\n",
    "            'able2Hov2', 'able2Hov3', 'able3Hov2', 'able3Hov3', 'able5Hov2', 'able5Hov3', 'able4Hov2', 'able4Hov3'\n",
    "        ])\n",
    "\n",
    "        # Convert time columns to datetime objects\n",
    "        df['startTime'] = pd.to_datetime(df['startTime'])\n",
    "        df['endTime'] = pd.to_datetime(df['endTime'])\n",
    "\n",
    "        # Convert startDay and endDay to the corresponding days of the week\n",
    "        days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "        start_day_index = days_of_week.index(df['startDay'].values[0])\n",
    "        end_day_index = days_of_week.index(df['endDay'].values[0])\n",
    "\n",
    "        # Calculate the number of days between the start and end days\n",
    "        days_difference = end_day_index - start_day_index + 1 if end_day_index >= start_day_index else 7 + end_day_index - start_day_index + 1\n",
    "\n",
    "        # Calculate the duration between startTime and endTime\n",
    "        duration = (df['endTime'].values[0] - df['startTime'].values[0])\n",
    "\n",
    "        # Check if the time period covers a full 24-hour period and spans all 7 days\n",
    "        return duration >= pd.Timedelta(days=1) and days_difference == 7\n",
    "\n",
    "    # Sample row data\n",
    "    row_data = [1040000, 'Montgomery', -1, 'Monday', '5:00:00', 'Wednesday', '10:00:00', 3, 3, -1, -1, 3, 3, 3, 3]\n",
    "\n",
    "    # Verify time completeness for the specific row\n",
    "    time_completeness_row_check = verify_time_completeness_for_row(row_data)\n",
    "    print(\"Time Completeness Check for Row:\", time_completeness_row_check)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
